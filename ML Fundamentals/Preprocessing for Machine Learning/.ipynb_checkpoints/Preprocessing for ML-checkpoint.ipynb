{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocesssing\n",
    "\n",
    "    This is typically a task that will have to be done after you have collected and cleaned your data. Let's jump right in: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: (665, 35)\n",
      "After drop: (665, 24)\n"
     ]
    }
   ],
   "source": [
    "#Dropping NA values. \n",
    "\n",
    "#For a dataframe, we use the .dropna() method. We can say if we want to \n",
    "#drop rows or columns with the 'axis' parameter, and we can say how many\n",
    "#NaN values we are willing to take with the 'thresh' parameter.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "\n",
    "volunteer = pd.read_csv('volunteer_opportunities.csv')\n",
    "\n",
    "#Check out data shape: \n",
    "print('Before drop:',volunteer.shape)\n",
    "\n",
    "#Drop columns that have at least 3 NaN values, then check shape again: \n",
    "volunteer = volunteer.dropna(axis=1,thresh=3)\n",
    "print('After drop:',volunteer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "(617, 24)\n"
     ]
    }
   ],
   "source": [
    "#We can also quickly check the number of null values and subset therefrom.\n",
    "#Check it out: \n",
    "\n",
    "# Check how many values are missing in the category_desc column\n",
    "print(volunteer['category_desc'].isnull().sum())\n",
    "\n",
    "# Subset the volunteer dataset\n",
    "volunteer_subset = volunteer[volunteer['category_desc'].notnull()]\n",
    "\n",
    "# Print out the shape of the subset\n",
    "print(volunteer_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types: \n",
    "\n",
    "We can check what data types we have for each of our columns by checking **df.dtypes**. \n",
    "\n",
    "We have the following data types: \n",
    "\n",
    "    a) object: string/mixed type\n",
    "    b) int64\n",
    "    c) float\n",
    "    d) etc...\n",
    "    \n",
    "    \n",
    "Sometimes, we'll see our column type is wrong. I.e. if we see an object dtype listed as string but it's clearly, say, a float, then we can do that by typing something like: **df[\"column\"].astype(\"float\")**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opportunity_id          int64\n",
       "content_id              int64\n",
       "vol_requests            int64\n",
       "event_time              int64\n",
       "title                  object\n",
       "hits                    int64\n",
       "summary                object\n",
       "is_priority            object\n",
       "category_id           float64\n",
       "category_desc          object\n",
       "org_title              object\n",
       "org_content_id          int64\n",
       "addresses_count         int64\n",
       "locality               object\n",
       "region                 object\n",
       "postalcode            float64\n",
       "display_url            object\n",
       "recurrence_type        object\n",
       "hours                   int64\n",
       "created_date           object\n",
       "last_modified_date     object\n",
       "start_date_date        object\n",
       "end_date_date          object\n",
       "status                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking column data types: \n",
    "volunteer.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    737\n",
      "1     22\n",
      "2     62\n",
      "3     14\n",
      "4     31\n",
      "Name: hits, dtype: int64\n",
      "opportunity_id          int64\n",
      "content_id              int64\n",
      "vol_requests            int64\n",
      "event_time              int64\n",
      "title                  object\n",
      "hits                    int32\n",
      "summary                object\n",
      "is_priority            object\n",
      "category_id           float64\n",
      "category_desc          object\n",
      "org_title              object\n",
      "org_content_id          int64\n",
      "addresses_count         int64\n",
      "locality               object\n",
      "region                 object\n",
      "postalcode            float64\n",
      "display_url            object\n",
      "recurrence_type        object\n",
      "hours                   int64\n",
      "created_date           object\n",
      "last_modified_date     object\n",
      "start_date_date        object\n",
      "end_date_date          object\n",
      "status                 object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Converting a column's dtype: \n",
    "# Print the head of the hits column\n",
    "print(volunteer[\"hits\"].head())\n",
    "\n",
    "# Convert the hits column to type int\n",
    "volunteer[\"hits\"] = volunteer[\"hits\"].astype(\"int\")\n",
    "\n",
    "# Look at the dtypes of the dataset\n",
    "print(volunteer.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with class imbalance: \n",
    "\n",
    "#### Stratified sampling: \n",
    "If we have some overall distribution of labeled data, but they are unbalanced, then a simple 3:1 sampling strategy might bias our model. Instead, we want to sample based on the observed distribution of classes, and we call this **stratified sampling**. \n",
    "\n",
    "Eg, if we had 100 samples broken down into 80=\"1\" and 20=\"2\", then for a training set of 75 samples, we want 60 Class 1 objects and 15 Class 2 objects. \n",
    "\n",
    "Conversely, in our test set of 25 damples, we'd want 20 Class 1 and 5 in Class 2. We can do this with sklearn's **train_test_split** function, with the *stratify* parameter. **We pass our list of y-values to the stratify parameter**. \n",
    "\n",
    "Let's practice using volunteer dataset, where we're trying to predict the category_desc variable: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Strengthening Communities    307\n",
       "Helping Neighbors in Need    119\n",
       "Education                     92\n",
       "Health                        52\n",
       "Environment                   32\n",
       "Emergency Preparedness        15\n",
       "Name: category_desc, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's first observe our class imbalance: \n",
    "volunteer.category_desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strengthening Communities    230\n",
      "Helping Neighbors in Need     89\n",
      "Education                     69\n",
      "Health                        39\n",
      "Environment                   24\n",
      "Emergency Preparedness        11\n",
      "Name: category_desc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Now we create a stratified sampling train_test_split: \n",
    "\n",
    "# Create a data with all columns except category_desc\n",
    "volunteer_X = volunteer.drop('category_desc', axis=1)\n",
    "\n",
    "# Create a category_desc labels dataset\n",
    "volunteer_y = volunteer[['category_desc']] #use double brackets to create\n",
    "#a DataFrame object, not just a series. \n",
    "\n",
    "# Use stratified sampling to split up the dataset according to the volunteer_y dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(volunteer_X, volunteer_y, stratify=volunteer_y)\n",
    "\n",
    "# Print out the category_desc counts on the training y labels\n",
    "print(y_train['category_desc'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Standardizing Data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is standardization? \n",
    "Many models assume normally distributed model, so we often need to transform our data to be normal for our models to be valid.\n",
    "\n",
    "Naturally, these are only applied to continous data.\n",
    "\n",
    "### When do we standard?\n",
    "\n",
    "    a) If we have a model in linear space (eg KNN)\n",
    "    b) Dataset features have high variance (especially one out of proportion to the others)\n",
    "    c) Dataset features are continous and on wildly different scales. \n",
    "    d) Linearity assumptions.\n",
    "\n",
    "### We will discuss 2 forms of standardization: \n",
    "    \n",
    "    a) Log-normalization:\n",
    "    \n",
    "    b) Feature scaling: \n",
    "    \n",
    "    More about these coming up...(!)\n",
    "    \n",
    "#### First, though, let's try seeing what happens below when we fail to standardize our data:\n",
    "\n",
    "Here we have a subset of the wine dataset. One of the columns, Proline, has an extremely high variance compared to the other columns. This is an example of where a technique like log normalization would come in handy, which you'll learn about in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfortunately, DataCamp didn't specify here what their X and y were. But\n",
    "#let's still check out the syntax:\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "# # Split the dataset and labels into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# # Fit the k-nearest neighbors model to the training data\n",
    "# knn.fit(X_train, y_train)\n",
    "\n",
    "# # Score the model on the test data\n",
    "# print(knn.score(X_test, y_test))\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "#Output: 0.688888888888 (pretty low...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-normalization:\n",
    "\n",
    "### What?\n",
    "Very useful when we have a column with high variance relative to others, which can seriously throw off classifiers.\n",
    "\n",
    "Log-normalization transforms values onto a scale that approximates normality, which helps it work with linearity-assuming models. \n",
    "\n",
    "#### Benefits: \n",
    "    a) Captures relative changes\n",
    "    b) Captures magnitude of change\n",
    "    c) Keeps everything in the positive space\n",
    "    \n",
    "    \n",
    "#### To perform log normalization, we use np.log() on the column we'd like to normalize. We first check variances, however, by using df.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99166.71735542428\n",
      "0.17231366191842018\n"
     ]
    }
   ],
   "source": [
    "wine = pd.read_csv('wine_types.csv')\n",
    "\n",
    "# Print out the variance of the Proline column\n",
    "print(wine[\"Proline\"].var())\n",
    "\n",
    "# Apply the log normalization function to the Proline column\n",
    "wine[\"Proline_log\"] = np.log(wine[\"Proline\"])\n",
    "\n",
    "# Check the variance of the Proline column again\n",
    "print(wine[\"Proline_log\"].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling: \n",
    "\n",
    "### What?\n",
    "This is a useful way of linearly comparing features. It centers features around 0 and transforms them to unit variance, with an approximately normal distribution. A requirement for many sklearn models...\n",
    "\n",
    "\n",
    "### Why might we use this, and how do we balance it with log normalization?\n",
    "\n",
    "If we have columns that are on significantly different scales, even if they have ~similar variances, then we will likely want to use feature scaling. We import a StandardScaler form sklearn.preprocessing (see below code on how to do this!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Proline_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.938202</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>6.530303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.775035</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>0.415107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>5.627621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>6.215606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>6.512486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>6.892642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>7.426549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Type     Alcohol  Malic acid         Ash  Alcalinity of ash  \\\n",
       "count  178.000000  178.000000  178.000000  178.000000         178.000000   \n",
       "mean     1.938202   13.000618    2.336348    2.366517          19.494944   \n",
       "std      0.775035    0.811827    1.117146    0.274344           3.339564   \n",
       "min      1.000000   11.030000    0.740000    1.360000          10.600000   \n",
       "25%      1.000000   12.362500    1.602500    2.210000          17.200000   \n",
       "50%      2.000000   13.050000    1.865000    2.360000          19.500000   \n",
       "75%      3.000000   13.677500    3.082500    2.557500          21.500000   \n",
       "max      3.000000   14.830000    5.800000    3.230000          30.000000   \n",
       "\n",
       "        Magnesium  Total phenols  Flavanoids  Nonflavanoid phenols  \\\n",
       "count  178.000000     178.000000  178.000000            178.000000   \n",
       "mean    99.741573       2.295112    2.029270              0.361854   \n",
       "std     14.282484       0.625851    0.998859              0.124453   \n",
       "min     70.000000       0.980000    0.340000              0.130000   \n",
       "25%     88.000000       1.742500    1.205000              0.270000   \n",
       "50%     98.000000       2.355000    2.135000              0.340000   \n",
       "75%    107.000000       2.800000    2.875000              0.437500   \n",
       "max    162.000000       3.880000    5.080000              0.660000   \n",
       "\n",
       "       Proanthocyanins  Color intensity         Hue  \\\n",
       "count       178.000000       178.000000  178.000000   \n",
       "mean          1.590899         5.058090    0.957449   \n",
       "std           0.572359         2.318286    0.228572   \n",
       "min           0.410000         1.280000    0.480000   \n",
       "25%           1.250000         3.220000    0.782500   \n",
       "50%           1.555000         4.690000    0.965000   \n",
       "75%           1.950000         6.200000    1.120000   \n",
       "max           3.580000        13.000000    1.710000   \n",
       "\n",
       "       OD280/OD315 of diluted wines      Proline  Proline_log  \n",
       "count                    178.000000   178.000000   178.000000  \n",
       "mean                       2.611685   746.893258     6.530303  \n",
       "std                        0.709990   314.907474     0.415107  \n",
       "min                        1.270000   278.000000     5.627621  \n",
       "25%                        1.937500   500.500000     6.215606  \n",
       "50%                        2.780000   673.500000     6.512486  \n",
       "75%                        3.170000   985.000000     6.892642  \n",
       "max                        4.000000  1680.000000     7.426549  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, say that we want to build a linear model using three of our variables:\n",
    "\n",
    "# Create the scaler\n",
    "ss = StandardScaler() #create a standard scaler\n",
    "\n",
    "# Take a subset of the DataFrame you want to scale \n",
    "wine_subset = wine[['Ash','Alcalinity of ash','Magnesium']]\n",
    "\n",
    "# Apply the scaler to the DataFrame subset\n",
    "wine_subset_scaled = ss.fit_transform(wine_subset) #fit your scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a73f0e3dce16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Apply the scaling method to the dataset used for modeling.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mX_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#Now, going back to our \"dummy\" example above, let's see what our accuracy\n",
    "#would look like after we scale (again, DataCamp hides this data from us,\n",
    "#but we can reasonably infer...)\n",
    "\n",
    "# #--------------------------\n",
    "# # Split the dataset and labels into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "# # Fit the k-nearest neighbors model to the training data\n",
    "# knn.fit(X_train, y_train)\n",
    "\n",
    "# # Score the model on the test data\n",
    "# print(knn.score(X_test, y_test))\n",
    "# #--------------------------\n",
    "\n",
    "\n",
    "\n",
    "# Create the scaling method.\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Apply the scaling method to the dataset used for modeling.\n",
    "X_scaled = ss.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data.\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Score the model on the test data.\n",
    "print(knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Feature Engineering \n",
    "\n",
    "## What?\n",
    "\n",
    "Creation of new features based on existing features. Often gives insight into relationships between features. Use it to extract and expand data.\n",
    "\n",
    "Keep in mind that feature engineering is quite dataset-dependent, often requiring domain-level expertise. \n",
    "\n",
    "## Categorical variables:\n",
    "\n",
    "Categorical variables for sklearn models must be **encoded!**. We can encode variables using either pandas or sklearn. \n",
    "\n",
    "Eg: In pandas, we might use **df[col_name].apply(lambda val: 1 if val == \"y\" else 0)**\n",
    "\n",
    "Eg: In sklearn, we use a label encoder. This will be particularly useful if we want to incorporate label encoding into an sklearn pipeline:\n",
    "\n",
    "**from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder()\n",
    "df['encoded var name'] = le.fit_transform(df['unencoded var name'])**\n",
    "\n",
    "### One-hot encoding: \n",
    "This is a useful way of encoding when you have more than 2 variables that you want to code. You can do this in pandas by the following means: \n",
    "**pd.get_dummies(df['col name'])**. For an n-level categorical variable, it will create n additional columns in your new dataframe. \n",
    "\n",
    "\n",
    "#### A note about our upcoming exercises:\n",
    "Dope. For this exercise, we'll be looking at a hiking dataframe. Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accessible_enc Accessible\n",
      "0               1          Y\n",
      "1               0          N\n",
      "2               0          N\n",
      "3               0          N\n",
      "4               0          N\n"
     ]
    }
   ],
   "source": [
    "#import dataset for this chapter\n",
    "hiking = pd.read_json('hiking.json')\n",
    "\n",
    "#Ok, let's do our first round of encoding!\n",
    "\n",
    "# Set up the LabelEncoder object\n",
    "enc = LabelEncoder()\n",
    "\n",
    "# Apply the encoding to the \"Accessible\" column\n",
    "hiking[\"Accessible_enc\"] = enc.fit_transform(hiking[\"Accessible\"])\n",
    "\n",
    "# Compare the two columns\n",
    "print(hiking[[\"Accessible_enc\", \"Accessible\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Education  Emergency Preparedness  Environment  Health  \\\n",
      "0          0                       0            0       0   \n",
      "1          0                       0            0       0   \n",
      "2          0                       0            0       0   \n",
      "3          0                       0            0       0   \n",
      "4          0                       0            1       0   \n",
      "\n",
      "   Helping Neighbors in Need  Strengthening Communities  \n",
      "0                          0                          0  \n",
      "1                          0                          1  \n",
      "2                          0                          1  \n",
      "3                          0                          1  \n",
      "4                          0                          0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One-hot encoding:\n",
    "\n",
    "# Transform the category_desc column\n",
    "category_enc = pd.get_dummies(volunteer[\"category_desc\"])\n",
    "\n",
    "# Take a look at the encoded columns\n",
    "print(category_enc.head())\n",
    "type(category_enc)\n",
    "#as you see below, the get_dummies method\n",
    "#actually just returns a DataFrame. So I suppose you have to concatenate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering numerical features\n",
    "\n",
    "### Aggregate statistics:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     city  day1  day2  day3\n",
      "0     nyc    68    67    66\n",
      "1      sf    75    70    80\n",
      "2      la    80    82    77\n",
      "3  boston    63    59    69\n"
     ]
    }
   ],
   "source": [
    "quick_dict = {'city':['nyc','sf','la','boston'], 'day1':[68,75,80,63],\n",
    "             'day2':[67,70,82,59],'day3':[66,80,77,69]}\n",
    "\n",
    "example = pd.DataFrame(quick_dict)\n",
    "\n",
    "print(example)\n",
    "\n",
    "columns = ['day1','day2','day3']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>day1</th>\n",
       "      <th>day2</th>\n",
       "      <th>day3</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nyc</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sf</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>la</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>79.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boston</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>69</td>\n",
       "      <td>63.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city  day1  day2  day3       mean\n",
       "0     nyc    68    67    66  67.000000\n",
       "1      sf    75    70    80  75.000000\n",
       "2      la    80    82    77  79.666667\n",
       "3  boston    63    59    69  63.666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dope, now that we have our dataset, let's calculate the mean of the days\n",
    "#for each city: \n",
    "\n",
    "example['mean'] = example.apply(lambda row: row[columns].mean(),axis=1)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try some date-time processing: \n",
    "\n",
    "the **pd.to_datetime** method is incredibly useful here. \n",
    "\n",
    "Additionally, once we've got datetime objects in a column, we can work \n",
    "with their inherent attributes like **.month**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>July 30 2011</td>\n",
       "      <td>$45.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February 01 2011</td>\n",
       "      <td>$56.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January 29 2011</td>\n",
       "      <td>29.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>March 31 2012</td>\n",
       "      <td>49.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date purchase\n",
       "0      July 30 2011   $45.08\n",
       "1  February 01 2011   $56.08\n",
       "2   January 29 2011    29.29\n",
       "3     March 31 2012    49.28"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's create a dataframe with some raw month data\n",
    "\n",
    "date_dict = {'date':['July 30 2011','February 01 2011',\n",
    "                      'January 29 2011','March 31 2012'], 'purchase':[\n",
    "    '$45.08','$56.08','29.29','49.28']}\n",
    "\n",
    "dates = pd.DataFrame(date_dict)\n",
    "\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>purchase</th>\n",
       "      <th>date converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>July 30 2011</td>\n",
       "      <td>$45.08</td>\n",
       "      <td>2011-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February 01 2011</td>\n",
       "      <td>$56.08</td>\n",
       "      <td>2011-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January 29 2011</td>\n",
       "      <td>29.29</td>\n",
       "      <td>2011-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>March 31 2012</td>\n",
       "      <td>49.28</td>\n",
       "      <td>2012-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date purchase date converted\n",
       "0      July 30 2011   $45.08     2011-07-30\n",
       "1  February 01 2011   $56.08     2011-02-01\n",
       "2   January 29 2011    29.29     2011-01-29\n",
       "3     March 31 2012    49.28     2012-03-31"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's extract date-time objects: \n",
    "\n",
    "dates['date converted'] = pd.to_datetime(dates['date'])\n",
    "\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, finally, let's just grab the month from each one: \n",
    "\n",
    "dates['month'] = dates['date converted'].apply(lambda row: row.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  start_date_converted  start_date_month\n",
      "0           2011-07-30                 7\n",
      "1           2011-02-01                 2\n",
      "2           2011-01-29                 1\n",
      "3           2011-02-14                 2\n",
      "4           2011-02-05                 2\n"
     ]
    }
   ],
   "source": [
    "#Some more practice with the volunteers dataset on datetime: \n",
    "\n",
    "# First, convert string column to date column\n",
    "volunteer[\"start_date_converted\"] = pd.to_datetime(volunteer[\"start_date_date\"])\n",
    "\n",
    "# Extract just the month from the converted column\n",
    "volunteer[\"start_date_month\"] = volunteer[\"start_date_converted\"].apply(lambda row: row.month)\n",
    "\n",
    "# Take a look at the original and new columns\n",
    "print(volunteer[[\"start_date_converted\", \"start_date_month\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification:\n",
    "\n",
    "### tf-idf vectors: What?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a pattern to extract numbers and decimals\n",
    "def return_mileage(length):\n",
    "    pattern = re.compile(r\"\\d+\\.\\d+\")\n",
    "    \n",
    "    # Search the text for matches\n",
    "    mile = re.match(pattern, length)\n",
    "    \n",
    "    # If a value is returned, use group(0) to return the found value\n",
    "    if mile is not None:\n",
    "        return float(mile.group(0))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Selecting Features\n",
    "\n",
    "## When?\n",
    "Sometimes we have redundant information in our datasets (i.e., city, state, latitude and longitude). Additionally, sometimes we find that some of our features are statistically correlated, which breaks the assumptions of certain models. \n",
    "\n",
    "## Removing redundant features: \n",
    "Broadly, there are a few situations in which we might consider features redundant:\n",
    "\n",
    "    a) The features are noisy\n",
    "    \n",
    "    b) The features are correlated in some way...\n",
    "    \n",
    "## Correlated features: \n",
    "\n",
    "We can use Pearson's correlation coefficient to check a feature set for correlation. This can quite easily be done with the **df.corr()** method!\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Type   Alcohol  Malic acid       Ash  \\\n",
      "Type                          1.000000 -0.328222    0.437776 -0.049643   \n",
      "Alcohol                      -0.328222  1.000000    0.094397  0.211545   \n",
      "Malic acid                    0.437776  0.094397    1.000000  0.164045   \n",
      "Ash                          -0.049643  0.211545    0.164045  1.000000   \n",
      "Alcalinity of ash             0.517859 -0.310235    0.288500  0.443367   \n",
      "Magnesium                    -0.209179  0.270798   -0.054575  0.286587   \n",
      "Total phenols                -0.719163  0.289101   -0.335167  0.128980   \n",
      "Flavanoids                   -0.847498  0.236815   -0.411007  0.115077   \n",
      "Nonflavanoid phenols          0.489109 -0.155929    0.292977  0.186230   \n",
      "Proanthocyanins              -0.499130  0.136698   -0.220746  0.009652   \n",
      "Color intensity               0.265668  0.546364    0.248985  0.258887   \n",
      "Hue                          -0.617369 -0.071747   -0.561296 -0.074667   \n",
      "OD280/OD315 of diluted wines -0.788230  0.072343   -0.368710  0.003911   \n",
      "Proline                      -0.633717  0.643720   -0.192011  0.223626   \n",
      "Proline_log                  -0.569246  0.637325   -0.152643  0.238394   \n",
      "\n",
      "                              Alcalinity of ash  Magnesium  Total phenols  \\\n",
      "Type                                   0.517859  -0.209179      -0.719163   \n",
      "Alcohol                               -0.310235   0.270798       0.289101   \n",
      "Malic acid                             0.288500  -0.054575      -0.335167   \n",
      "Ash                                    0.443367   0.286587       0.128980   \n",
      "Alcalinity of ash                      1.000000  -0.083333      -0.321113   \n",
      "Magnesium                             -0.083333   1.000000       0.214401   \n",
      "Total phenols                         -0.321113   0.214401       1.000000   \n",
      "Flavanoids                            -0.351370   0.195784       0.864564   \n",
      "Nonflavanoid phenols                   0.361922  -0.256294      -0.449935   \n",
      "Proanthocyanins                       -0.197327   0.236441       0.612413   \n",
      "Color intensity                        0.018732   0.199950      -0.055136   \n",
      "Hue                                   -0.273955   0.055398       0.433681   \n",
      "OD280/OD315 of diluted wines          -0.276769   0.066004       0.699949   \n",
      "Proline                               -0.440597   0.393351       0.498115   \n",
      "Proline_log                           -0.416897   0.424006       0.431205   \n",
      "\n",
      "                              Flavanoids  Nonflavanoid phenols  \\\n",
      "Type                           -0.847498              0.489109   \n",
      "Alcohol                         0.236815             -0.155929   \n",
      "Malic acid                     -0.411007              0.292977   \n",
      "Ash                             0.115077              0.186230   \n",
      "Alcalinity of ash              -0.351370              0.361922   \n",
      "Magnesium                       0.195784             -0.256294   \n",
      "Total phenols                   0.864564             -0.449935   \n",
      "Flavanoids                      1.000000             -0.537900   \n",
      "Nonflavanoid phenols           -0.537900              1.000000   \n",
      "Proanthocyanins                 0.652692             -0.365845   \n",
      "Color intensity                -0.172379              0.139057   \n",
      "Hue                             0.543479             -0.262640   \n",
      "OD280/OD315 of diluted wines    0.787194             -0.503270   \n",
      "Proline                         0.494193             -0.311385   \n",
      "Proline_log                     0.410494             -0.275675   \n",
      "\n",
      "                              Proanthocyanins  Color intensity       Hue  \\\n",
      "Type                                -0.499130         0.265668 -0.617369   \n",
      "Alcohol                              0.136698         0.546364 -0.071747   \n",
      "Malic acid                          -0.220746         0.248985 -0.561296   \n",
      "Ash                                  0.009652         0.258887 -0.074667   \n",
      "Alcalinity of ash                   -0.197327         0.018732 -0.273955   \n",
      "Magnesium                            0.236441         0.199950  0.055398   \n",
      "Total phenols                        0.612413        -0.055136  0.433681   \n",
      "Flavanoids                           0.652692        -0.172379  0.543479   \n",
      "Nonflavanoid phenols                -0.365845         0.139057 -0.262640   \n",
      "Proanthocyanins                      1.000000        -0.025250  0.295544   \n",
      "Color intensity                     -0.025250         1.000000 -0.521813   \n",
      "Hue                                  0.295544        -0.521813  1.000000   \n",
      "OD280/OD315 of diluted wines         0.519067        -0.428815  0.565468   \n",
      "Proline                              0.330417         0.316100  0.236183   \n",
      "Proline_log                          0.290203         0.348970  0.173593   \n",
      "\n",
      "                              OD280/OD315 of diluted wines   Proline  \\\n",
      "Type                                             -0.788230 -0.633717   \n",
      "Alcohol                                           0.072343  0.643720   \n",
      "Malic acid                                       -0.368710 -0.192011   \n",
      "Ash                                               0.003911  0.223626   \n",
      "Alcalinity of ash                                -0.276769 -0.440597   \n",
      "Magnesium                                         0.066004  0.393351   \n",
      "Total phenols                                     0.699949  0.498115   \n",
      "Flavanoids                                        0.787194  0.494193   \n",
      "Nonflavanoid phenols                             -0.503270 -0.311385   \n",
      "Proanthocyanins                                   0.519067  0.330417   \n",
      "Color intensity                                  -0.428815  0.316100   \n",
      "Hue                                               0.565468  0.236183   \n",
      "OD280/OD315 of diluted wines                      1.000000  0.312761   \n",
      "Proline                                           0.312761  1.000000   \n",
      "Proline_log                                       0.254218  0.977423   \n",
      "\n",
      "                              Proline_log  \n",
      "Type                            -0.569246  \n",
      "Alcohol                          0.637325  \n",
      "Malic acid                      -0.152643  \n",
      "Ash                              0.238394  \n",
      "Alcalinity of ash               -0.416897  \n",
      "Magnesium                        0.424006  \n",
      "Total phenols                    0.431205  \n",
      "Flavanoids                       0.410494  \n",
      "Nonflavanoid phenols            -0.275675  \n",
      "Proanthocyanins                  0.290203  \n",
      "Color intensity                  0.348970  \n",
      "Hue                              0.173593  \n",
      "OD280/OD315 of diluted wines     0.254218  \n",
      "Proline                          0.977423  \n",
      "Proline_log                      1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16063a90518>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "examp_mat = wine.corr()\n",
    "\n",
    "# Print out the column correlations of the wine dataset\n",
    "print(wine.corr())\n",
    "\n",
    "# Take a minute to find the column where the correlation value is greater than 0.75 at least twice\n",
    "to_drop = \"Flavanoids\"\n",
    "\n",
    "# Drop that column from the DataFrame\n",
    "wine = wine.drop(to_drop, axis=1)\n",
    "\n",
    "sns.heatmap(examp_mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick note about dropping correlated features: \n",
    "\n",
    "Dropping correlated features is often an iterative process, so you may need to try different combinations in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(examp_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's practice with the volunteer dataset: \n",
    "\n",
    "# Create a list of redundant column names to drop\n",
    "to_drop = [\"category_desc\", \"created_date\", \"locality\", \"region\", \"vol_requests\"]\n",
    "\n",
    "# Drop those columns from the dataset\n",
    "volunteer_subset = volunteer.drop(to_drop, axis=1)\n",
    "\n",
    "# Print out the head of the new dataset\n",
    "print(volunteer_subset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction: PCA\n",
    "\n",
    "Dimensionality reduction is an unsupervised method of learning that combines and decomposes a feature space. Here, we will focus on PCA\n",
    "\n",
    "### Some guidance/caveat for PCA:\n",
    "\n",
    "    a) It is a black box model...very unexplainable. \n",
    "    \n",
    "    b) Only do PCA at the end of your preprocessing journey. \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a model implementation of PCA:\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA()\n",
    "\n",
    "# df_pca = pca.fit_transform(df)\n",
    "\n",
    "# print(df_pca)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.98098724e-01 1.73593316e-03 9.43288311e-05 4.89462522e-05\n",
      " 1.04706853e-05 5.61289777e-06 2.79970917e-06 1.44536069e-06\n",
      " 9.76685744e-07 3.94374158e-07 2.15136165e-07 9.01993593e-08\n",
      " 6.27152353e-08]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5777777777777777"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Set up PCA and the X vector for diminsionality reduction\n",
    "knn = KNeighborsClassifier()\n",
    "pca = PCA()\n",
    "wine_X = wine.drop(\"Type\", axis=1)\n",
    "y = wine['Type']\n",
    "\n",
    "# Apply PCA to the wine dataset X vector\n",
    "transformed_X = pca.fit_transform(wine_X)\n",
    "\n",
    "# Look at the percentage of variance explained by the different components\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# Split the transformed X and the y labels into training and test sets\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(transformed_X, y)\n",
    "\n",
    "# Fit knn to the training data\n",
    "knn.fit(X_wine_train,y_wine_train)\n",
    "\n",
    "# Score knn on the test data and print it out\n",
    "knn.score(X_wine_test,y_wine_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
