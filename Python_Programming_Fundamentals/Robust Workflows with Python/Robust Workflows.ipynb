{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #In thi scourse, you'll learn to write Python code that is easy to:\n",
    "#     #Read\n",
    "#     #Use\n",
    "#     #Maintain \n",
    "#     #Share\n",
    "#     #Develop your own personal workflow\n",
    "    \n",
    "# #Principle 1: Don't Repeat Yourself!\n",
    "\n",
    "#     #A useful way of doing this is creating functions: \n",
    "\n",
    "# #E.g.\n",
    "# def read(filename):\n",
    "#     with open(filename, 'r') as file: \n",
    "#         return file.read()\n",
    "    \n",
    "# #However, if we have multiple files and don't want to repeat our\n",
    "# #read() function call, we can use a list comprehension: \n",
    "\n",
    "# #eg imagine we had the following files in our CWD: \n",
    "# filenames = ['diabetes.txt','boston.txt','iris.txt']\n",
    "\n",
    "# #read files with a list comprehension: \n",
    "# diabetes, boston, iris = [read(f) for f in filenames]\n",
    "\n",
    "## There, in the above line, we used a list comprehension with our \n",
    "##custom function. Neat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #the Path class: \n",
    "\n",
    "# #The Path class opens and closes files automatically, without\n",
    "# #needing a 'with' statment. pathlib is included as part of std\n",
    "# #library:\n",
    "\n",
    "## Eg, the below lines are equivalent to what we've written above:\n",
    "\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "# #diabetes, boston, iris = [Path(f).read_text() for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #moreover, if we replace the square brackets above with () \n",
    "# #instead of [], we will create a *generator* object. \n",
    "\n",
    "# #generator objects save memory over list comprehensions. Eg: \n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "# diabetes, boston, iris = (Path(f).read_text() for f in filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__fspath__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '_accessor',\n",
       " '_cached_cparts',\n",
       " '_closed',\n",
       " '_cparts',\n",
       " '_drv',\n",
       " '_format_parsed_parts',\n",
       " '_from_parsed_parts',\n",
       " '_from_parts',\n",
       " '_hash',\n",
       " '_init',\n",
       " '_make_child',\n",
       " '_make_child_relpath',\n",
       " '_opener',\n",
       " '_parse_args',\n",
       " '_parts',\n",
       " '_pparts',\n",
       " '_raise_closed',\n",
       " '_raw_open',\n",
       " '_root',\n",
       " '_str',\n",
       " 'absolute',\n",
       " 'anchor',\n",
       " 'as_posix',\n",
       " 'as_uri',\n",
       " 'chmod',\n",
       " 'cwd',\n",
       " 'drive',\n",
       " 'exists',\n",
       " 'expanduser',\n",
       " 'glob',\n",
       " 'group',\n",
       " 'home',\n",
       " 'is_absolute',\n",
       " 'is_block_device',\n",
       " 'is_char_device',\n",
       " 'is_dir',\n",
       " 'is_fifo',\n",
       " 'is_file',\n",
       " 'is_mount',\n",
       " 'is_reserved',\n",
       " 'is_socket',\n",
       " 'is_symlink',\n",
       " 'iterdir',\n",
       " 'joinpath',\n",
       " 'lchmod',\n",
       " 'lstat',\n",
       " 'match',\n",
       " 'mkdir',\n",
       " 'name',\n",
       " 'open',\n",
       " 'owner',\n",
       " 'parent',\n",
       " 'parents',\n",
       " 'parts',\n",
       " 'read_bytes',\n",
       " 'read_text',\n",
       " 'relative_to',\n",
       " 'rename',\n",
       " 'replace',\n",
       " 'resolve',\n",
       " 'rglob',\n",
       " 'rmdir',\n",
       " 'root',\n",
       " 'samefile',\n",
       " 'stat',\n",
       " 'stem',\n",
       " 'suffix',\n",
       " 'suffixes',\n",
       " 'symlink_to',\n",
       " 'touch',\n",
       " 'unlink',\n",
       " 'with_name',\n",
       " 'with_suffix',\n",
       " 'write_bytes',\n",
       " 'write_text']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total side note, but...\n",
    "\n",
    "#btw, to see all of an object's possible methods, simply use\n",
    "#the dir() function. Eg: \n",
    "\n",
    "dir(Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Using functions*: For loops vs. list comprehensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examples: \n",
    "\n",
    "#here are two functions: \n",
    "def print_files(filenames):\n",
    "    # Set up the loop iteration instructions\n",
    "    for name in filenames:\n",
    "        # Use pathlib.Path to print out each file\n",
    "        print(Path(name).read_text())\n",
    "        \n",
    "def list_files(filenames):\n",
    "    # Use pathlib.Path to read the contents of each file\n",
    "    return [Path(name).read_text()\n",
    "            # Obtain each name from the list of filenames\n",
    "            for name in filenames]\n",
    "\n",
    "# filenames = 'diabetes.txt', 'boston.txt', 'digits.txt', 'iris.txt', 'wine.txt'\n",
    "# print_files(filenames)\n",
    "# file_contents = list_files(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Amping up our list comprehensions with conditionals and multiple arguments:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(filename, query):\n",
    "    # Obtain lines from the input file\n",
    "    return [line for line in Path(filename).open()\n",
    "            # Filter the list comprehension\n",
    "            if query in line]\n",
    "\n",
    "# Iterate over files to find all matching lines\n",
    "matches = [get_matches(name, 'Number of') for name in filenames]\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now, let's step it up a little with a double for loop in our list comprehension*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will check out elements of a nested list (i.e. list \n",
    "#of lists):\n",
    "def flatten(nested_list):\n",
    "    return (element \n",
    "            # Obtain each list from the list of lists\n",
    "            for sublist in nested_list\n",
    "            # Obtain each string from every list\n",
    "            for element in sublist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*What is the above doing?* Simply, it is the equivalent of \n",
    "#the following function:: \n",
    "\n",
    "def flatten(nested_list):\n",
    "    for sublist in nested_list: \n",
    "        for element in sublist:\n",
    "            return element\n",
    "#But what we wrote above looks much prettier, right? Double for loops\n",
    "#are non-Pythonic and kinda ugly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, keep in mind that when used our get_matches() function to generate our matches variable above, we were using a list comprehension on a list of filenames. Thus, we were returning a list of lists. So, let's try something: \n",
    "\n",
    "# Let's flatten that result, then find above was returning a list of lists. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A note on generator objects**\n",
    "\n",
    "Generators remember which values they have already generated. This allows us to use the zip() function to elegantly pair the numbers we will extract below from the matches variable. As zip() pairs numbers, the number generator will keep track of which numbers come next until it runs out of values.\n",
    "\n",
    "After we use zip() to pair up the number of rows and columns from each dataset description, we will use zip() again to match dataset names and dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1f7dd6db8260>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m number_generator = (int(substring) for string in flatten(matches)\n\u001b[0m\u001b[0;32m      3\u001b[0m                     for substring in string.split() if substring.isdigit())\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matches' is not defined"
     ]
    }
   ],
   "source": [
    "# #\n",
    "\n",
    "# number_generator = (int(substring) for string in flatten(matches)\n",
    "#                     for substring in string.split() if substring.isdigit())\n",
    "# print(dict(zip(filenames, zip(number_generator, number_generator))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The modularity principle: \n",
    "\n",
    "#We want to write code as independent re-usable objects, like \n",
    "#the objects we wrote in previous examples. \n",
    "\n",
    "#Each object only has one job. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules and Scripts: \n",
    "\n",
    "\n",
    "modules and scripts are .py files. \n",
    "\n",
    "**Key difference between modules and scripts:**\n",
    "    a) Modules are imported to provide tools\n",
    "    \n",
    "        --> They define functions\n",
    "        \n",
    "    b) Scripts are run to perform actions\n",
    "    \n",
    "        --> they call functions\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An important word about \"if __name__ == '__main__':\n",
    "\n",
    "Let's say that you've written a model with the following function: \n",
    "\n",
    "\"def hello(): print(\"Hello World!\") \n",
    "hello\"\n",
    "\n",
    "Now, if I run this module as a script, I'll see the words \"Hello World!\" appear. But, if I simply import that module into another script and then run that other script, I will again see \"Hello World!\". This is becase the import statement will run my module script from top to bottom whether I like it or not. I may not want that to be the case...\n",
    "\n",
    "*Why not?*\n",
    "If I write a module for the sake of collecting useful functions in one place, I want to selectively use those functions, not have them run all at once in some external script. At the same time, if my module is meant to be run as a script at certain times, I also don't want to hide all my internally-defined function calls. So how do we enable dual functionality? Enter \"if __name__ = '__main__':\"\n",
    "\n",
    "**The __name__ variable**:\n",
    "When we run a file *as a script*, __name__ is equal to __main__. When this is the case, we execute the code blocks that follow if __name__ = __main__. In this way, we can enable a module to run as a script. \n",
    "\n",
    "# Generally, the __name__ variable gives *title* if we are importing title.py as a module, and __main__ if we are running title.py as a script!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract words\n",
    "\n",
    "In the next two exercises, you will define three functions that can be combine to extract and count words from a text file.\n",
    "\n",
    "The obtain_words() function uses a conditional expression to replace non-letter characters with spaces so that it can return words without punctuation.\n",
    "\n",
    "The filter_words() function use a list comprehension with an if clause to remove words shorter than the minimum_length threshold.\n",
    "\n",
    "After we confirm that these two functions work correctly, we will move them into a module. As we continue to work towards our current goal, we can build up a toolbox of functions that may come in handy for future tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def obtain_words(string):\n",
    "    # Replace non-alphabetic characters with spaces\n",
    "    return ''.join(char if char.isalpha() else ' ' for char in string).split()\n",
    "\n",
    "def filter_words(words, minimum_length=3):\n",
    "    # Remove words shorter than 3 characters\n",
    "    return [word for word in words if len(word) >= minimum_length]\n",
    "\n",
    "# # Use a string method to convert the text to lowercase\n",
    "# words = obtain_words(Path('diabetes.txt').read_text().lower())\n",
    "# filtered_words = filter_words(words)\n",
    "# print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent words\n",
    "\n",
    "In the previous exercise, we created a list of words. Now we will define a count_words() function to turn the word list into a dictionary of words and word counts. To accomplish this, we will use a dictionary comprehension.\n",
    "\n",
    "**Dictionary comprehensions create key-value pairs from an iterable.** In this case, the iterable is the word list, the dictionary keys are words, and the values are the word counts. After we create the dictionary, we will use turn it into a pandas DataFrame, so that we can use a series of methods to\n",
    "\n",
    "    a) sort the word counts\n",
    "    b) obtain the top 5 most frequent words\n",
    "    c) create a horizontal bar plot\n",
    "    d) remove the y axis label\n",
    "\n",
    "The bar plot will show the frequency of the top words in the diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x00000178A1190B88>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# #\n",
    "\n",
    "# number_generator = (int(substring) for string in flatten(matches)\n",
    "#                     for substring in string.split() if substring.isdigit())\n",
    "# print(dict(zip(filenames, zip(number_generator, number_generator))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Real quick: here's an example with dictionary comprehensions! \n",
    "\n",
    "list2 = [1,2,3,4,5,6,7]\n",
    "\n",
    "test_dict = {e: list2.index(e)+1 for e in list2}\n",
    "\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c5d794a2a2fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Create the dictionary of words and word counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mword_count_dictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m (pd.DataFrame(word_count_dictionary.items())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_words' is not defined"
     ]
    }
   ],
   "source": [
    "# #Dictionary comprehensions!\n",
    "# def count_words(word_list):\n",
    "#     # Count the words in the input list\n",
    "#     return {word: word_list.count(word) for word in word_list}\n",
    "\n",
    "# # Create the dictionary of words and word counts\n",
    "# word_count_dictionary = count_words(filtered_words)\n",
    "\n",
    "# (pd.DataFrame(word_count_dictionary.items())\n",
    "#  .sort_values(by=1, ascending=False)\n",
    "#  .head()\n",
    "#  .plot(x=0, kind='barh', xticks=range(5), legend=False)\n",
    "#  .set_ylabel(\"\")\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstraction!\n",
    "\n",
    "Why abstraction? Hide implementation details, design user interfaces, facilitate code use\n",
    "\n",
    "Classes (see below): Clases are templates for creating Python objects, and the process of *creating class instances* is called **instantiation!** Note that the **self** parameter represents an instance of the class. \n",
    "\n",
    "We can define instance **attributes** after the def __init__...  statement. We can also use these attributes as part of instance **methods**. \n",
    "\n",
    "Using methods in a series is called method chaining!\n",
    "\n",
    "\n",
    "## Class attributes: \n",
    "\n",
    "Class attributes are attributes assigned to a class but outside __init__\n",
    "\n",
    "\n",
    "## Class methods: \n",
    "Class method definitions are preceded by the @classmethod **decorator**. In the case of clas methods, you must use the **cls** keyword, which represents the *class* and not the *class instance*.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's practice defining a TextFile class that can represent any \n",
    "#possible text file: \n",
    "\n",
    "from pathlib import Path \n",
    "\n",
    "class TextFile: \n",
    "    instances = [] #a class attribute\n",
    "    \n",
    "    def __init__(self, file):\n",
    "        self.text = Path(file).read_text() #self ehere refers to\n",
    "        #an instance of the TextFile class!\n",
    "        \n",
    "        self.words = ''.join(c if c.isalpha() else ' ' for c in self.text).split()\n",
    "        \n",
    "        self.__class__.instances.append(file) #define a class attribute \n",
    "        #that will be shared by all instances of the TextFile class\n",
    "        \n",
    "    def len_dict(self):\n",
    "        return {word: len(word) for word in self.words}\n",
    "        \n",
    "    @classmethod #a class method!!!\n",
    "    def instantiate(cls, filenames): #this applies to whole class, not just\n",
    "        #a single instance...\n",
    "        return map(cls,filenames) #this lets us instantiate with all filenames\n",
    "    \n",
    "        #alternatively to above line, could write: \n",
    "       # return (cls(filename) for filename in filenames)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continued...\n",
    "\n",
    "Now you can instantiate a single instance of the TextFile class as before with say, iris - TextFile('iris.txt'). \n",
    "\n",
    "OR, you can instantiate multiple instances at once. Eg: \n",
    "\n",
    "boston, diabetes = TextFile.instantiate(['boston.txt','diabetes.txt'])\n",
    "\n",
    "*Additionally, if you call TextFile.instances, you will be returned a list:* ['iris.txt','boston.txt','diabetes.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance method\n",
    "\n",
    "In this exercise, we will work with a class called ScikitData that represents datasets from the popular Python machine learning library scikit-learn.\n",
    "\n",
    "ScikitData has already been defined. In this exercise, we will define an instance method called pair_plot() and add it to ScikitData. **It is best practice to include all methods in the class definition, but we will add methods to ScikitData on the fly, so that we can build the class sequentially without redefining it.**\n",
    "\n",
    "Our pair_plot() instance method will plot dataset variables against each other using the pairplot() function, which has already been imported from the seaborn library.\n",
    "\n",
    "Before we can use pair_plot() to make a scatterplot matrix, we will have to create a ScikitData instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the first parameter in the pair_plot() definition\n",
    "def pair_plot(self, vars=range(3), hue=None):\n",
    "    return pairplot(pd.DataFrame(self.data), \n",
    "                    vars=vars, \n",
    "                    hue=hue, \n",
    "                    kind='reg')\n",
    "\n",
    "ScikitData.pair_plot = pair_plot\n",
    "\n",
    "# Create the diabetes instance of the ScikitData class\n",
    "diabetes = ScikitData('diabetes')\n",
    "\n",
    "# Call pairplot() to plot diabetes dataset variables\n",
    "diabetes.pair_plot(vars=range(2, 6), hue=1)._legend.remove()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary with a suuuuuper straightforward example of dynamically adding instance methods to a class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Toby, meow!, meow!, meow!\n",
      "woof?\n"
     ]
    }
   ],
   "source": [
    "#Notice, that you can add instance methods and objects on the fly as such:\n",
    "\n",
    "class Cat: \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def meow(self, num_meows=2):\n",
    "        print(\"My name is \"+ self.name + num_meows*\", meow!\")\n",
    "        \n",
    "    def instantiate(cls,\n",
    "\n",
    "#done defining, right? Well...let's now extend the Cat class: \n",
    "\n",
    "def woof(self): #defining on the fly!\n",
    "    print('woof?')\n",
    "    \n",
    "Cat.woof= woof\n",
    "\n",
    "toby = Cat('Toby')\n",
    "toby.name\n",
    "toby.meow(3)\n",
    "toby.woof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class method\n",
    "\n",
    "The pair_plot() method we defined in the previous exercise facilitates exploratory data analysis.\n",
    "\n",
    "If we have several datasets that we want to explore, it can be tedious to instantiate the ScikitData class repeatedly.\n",
    "\n",
    "To enable rapid instantiation of our ScikitData class, we will add a **class method called get_generator().**\n",
    "\n",
    "A class method is a good choice here, because we want to be able to access the class's ability to make new instances.\n",
    "\n",
    "We will use get_generator() to create a generator named dataset_generator that will generate instances that represent the diabetes and iris datasets.\n",
    "\n",
    "Instead of assigning the instances to variables, we will use a for loop and the pair_plot() instance method from the previous exercise to plot both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the decorator for the get_generator() definition\n",
    "@classmethod\n",
    "# Add the first parameter to the get_generator() definition\n",
    "def get_generator(cls, dataset_names):\n",
    "    return map(cls, dataset_names)\n",
    "\n",
    "ScikitData.get_generator = get_generator #dynamically adding class method\n",
    "\n",
    "# Create a generator for the diabetes and iris datasets\n",
    "dataset_generator = ScikitData.get_generator(['diabetes', 'iris'])\n",
    "\n",
    "# Iterate over each dataset in the dataset generator\n",
    "for dataset in dataset_generator:\n",
    "    dataset.pair_plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Documentation and Tests\n",
    "\n",
    "**Dynamic (Duck) Typing**:\n",
    "\n",
    "Python infers type when running code. For instance,  if we define def double(n): return n*2, we actually have no idea what \"n\" really is (a string? an int?). \n",
    "\n",
    "To address this ambiguity, we can add type hints in the function inputs via a semicolon, and add type hints in the function outputs via an arrow. See below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "def double(n:int) -> int: \n",
    "    return n*2\n",
    "print(double(2))\n",
    "\n",
    "\n",
    "def double_str(n:str)->str:\n",
    "    return  n*2\n",
    "\n",
    "print(double_str('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function double in module __main__:\n",
      "\n",
      "double(n: int) -> int\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(double) #help in this case reminds of your type hints!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docstrings:\n",
    "\n",
    "Docstrings can be included in definitions of functions, classes, and methods. They may also be included at the top of .py files!\n",
    "\n",
    "Here is an example below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleN:\n",
    "    \"\"\"The summary of what the class does. \n",
    "    Arguments:\n",
    "        n: A float that will be doubled.\n",
    "    Attributes:\n",
    "        n_doubled: A float that is the result of doubling n.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n: float) -> None:\n",
    "        self.n_doubled = n*2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports with Jupyter! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 (Starting to pick and choose...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several environment managers you might want to know about: \n",
    "    venv (part of Python standard library)\n",
    "    virtualenv (Widely-used)\n",
    "    pipenv (High-level interface)\n",
    "    conda (Not only for Python libraries!)\n",
    "    \n",
    "Dependency managers: \n",
    "    Dependency managers are tools that install and manage dependencies. \n",
    "    \n",
    "    Here is a quick list of dependency managers: \n",
    "        pip\n",
    "        pipenv\n",
    "        conda\n",
    "    \n",
    "    venv and virtualenv use pip\n",
    "    pipenv and conda manage both dependencies and environments\n",
    "    \n",
    "   \n",
    "   Dependency names and versions can be specified in dependency management files. For each dependency manager listed, its dependency management file is listed below: \n",
    "       pip --> requirements.txt\n",
    "       pipenv --> Pipfile\n",
    "       conda --> environment.yml\n",
    "       \n",
    "   *All three dependency managers use requirements.txt to specify exact or minimum dependencies* \n",
    "   \n",
    "### Steps for \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import venv, subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
