{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loadinge images\n",
    "\n",
    "Let's use the $\\texttt{imageio}$ package. It can read dicom files, which is very important. \n",
    "To read an image, we will call **imageio.imread()** on an image file. Image objects will be loaded in as numpy arrays. \n",
    "\n",
    "$\\underline{Metadata:}$\n",
    "\n",
    "Metadata = the who, what, whe acquisition. Image io loads available meta data into a dictionary using the **.meta** attribute, which takes the form of a dictionary. \n",
    "\n",
    "$\\underline{Plotting\\ images}$:\n",
    "\n",
    "Matplotlib's **imshow()** function displays 2d image data. Often, we will use **cmap = 'gray'**. Given that axis ticks and labels are often not useful for images, we will also call **plt.axis('off')**. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Examples of code can be found below (though, alas, datacamp does not give the image files for this course...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ImageIO\n",
    "import imageio\n",
    "\n",
    "# Load \"chest-220.dcm\"\n",
    "im = imageio.imread('chest-220.dcm')\n",
    "\n",
    "# Print image attributes\n",
    "print('Image type:', type(im))\n",
    "print('Shape of image array:', im.shape)\n",
    "\n",
    "# Import ImageIO and load image\n",
    "import imageio\n",
    "im = imageio.imread('chest-220.dcm')\n",
    "\n",
    "# Print the available metadata fields\n",
    "print(im.meta.keys())\n",
    "\n",
    "\n",
    "# Import ImageIO and PyPlot \n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read in \"chest-220.dcm\"\n",
    "#im = plt.imshow('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-dimensional images\n",
    "\n",
    "Volumetric, time-series (videos), and color images all of course have more than 2 dimensions, but can also be visualized as \"stacks\" of 2D arrays...\n",
    "\n",
    "imageio has a **.volread()** function, which can read multi-dimensional data directly and assemble a volume from multiple images (alternatively, numpy's **.stack()** function can also do this). It will actually check the available metadata to display multiple images in a stack in the correct order!!\n",
    "\n",
    "*Sampling rate*? This is the physical space covered by each element, and it is usually encoded in the image metadata for dicom files (in .meta['sampling'])\n",
    "\n",
    "The *field of view* is the physical space covered along each axis, and is the shape multiplied by the sampling rate. \n",
    "\n",
    "Ok, let's look at some code below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ImageIO and NumPy\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "# Read in each 2D image\n",
    "im1 = imageio.imread('chest-220.dcm')\n",
    "im2 = imageio.imread('chest-221.dcm')\n",
    "im3 = imageio.imread('chest-222.dcm')\n",
    "\n",
    "# Stack images into a volume\n",
    "vol = np.stack([im1,im2,im3], axis = 0)\n",
    "print('Volume dimensions:', vol.shape)\n",
    "\n",
    "# Import ImageIO\n",
    "import imageio\n",
    "\n",
    "# Load the \"tcia-chest-ct\" directory\n",
    "vol = imageio.volread('tcia-chest-ct')\n",
    "\n",
    "# Print image attributes\n",
    "print('Available metadata:', vol.meta.keys())\n",
    "print('Shape of image array:', vol.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Plotting: \n",
    "\n",
    "We can use **plt.subplots** to look at multiple slices of an image. Subplots will return two objects: a figure object and an axes object.\n",
    "\n",
    "Each element in our \"axes\" object will store a slice of the image. \n",
    "\n",
    "<img src=\"Capture.JPG\">\n",
    "\n",
    "And of course, if you have tons of images, you can bring a for loop. And note that you can change what axis you plot along to get coronal, transverse, and sagittal views.\n",
    "\n",
    "$\\underline{Modifying\\ the \\ aspect \\ ratio}$\n",
    "\n",
    "Now, many datasets do not have equal sampling rates across the different dimensions. You need to correct this so that your images are not distorted. We can determine the aspect by  normalizing sampling ratios to one another and passing the kwarg **aspect = ...** to imshow\n",
    "\n",
    "\n",
    "Let's practice...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyPlot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize figure and axes grid\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 1)\n",
    "\n",
    "# Draw an image on each subplot\n",
    "axes[0].imshow(im1, cmap = 'gray')\n",
    "axes[1].imshow(im2, cmap = 'gray')\n",
    "\n",
    "# Remove ticks/labels and render\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "plt.show()\n",
    "\n",
    "# To select a 2D frame, pick a frame for the first axis and \n",
    "# select all data from the remaining two: vol[0, :, :]\n",
    "\n",
    "    \n",
    "    # Plot the images on a subplots array \n",
    "fig, axes = plt.subplots(ncols = 4, nrows = 1)\n",
    "\n",
    "# Loop through subplots and draw image (plotting every 40th slice...)\n",
    "for ii in range(4):\n",
    "    im = vol[40*ii]\n",
    "    axes[ii].imshow(im, cmap='gray')\n",
    "    axes[ii].axis('off')\n",
    "    \n",
    "# Render the figure\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Select frame from \"vol\"\n",
    "im1 = vol[:, 256, :]\n",
    "im2 = vol[:,:,256]\n",
    "\n",
    "# Compute aspect ratios\n",
    "d0, d1, d2 = vol.meta['sampling']\n",
    "asp1 = d0 / d2\n",
    "asp2 = d0/d1\n",
    "\n",
    "# Plot the images on a subplots array \n",
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "axes[0].imshow(im1, cmap='gray', aspect = asp1)\n",
    "axes[1].imshow(im2,cmap = 'gray', aspect = asp2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result of the last block of code above looks like this: \n",
    "\n",
    "<img src=\"coron_sag.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Intensities: Masks and filters\n",
    "\n",
    "To leverage masks and filters, you need an idea of what the intensity distribution of your pixels looks like. \n",
    "\n",
    "The range of values of pixels is determined by the data type. And unsigned integers (range from 0 to 255) are generally preferred because they convey a good amount of information while taking up a relatively small amount of memory. Many images will often be scaled by the value 255.\n",
    "\n",
    "SciPy, and especially its **Ndimage** module, contains some essential tools for image analysis. Advanced techniques and functionality also contained in **scikit-image**.\n",
    "\n",
    "To look at histogram of our pixel values we'll call **ndi.histogram(im,min=0,max=255,bins=256**)\n",
    "\n",
    "$\\underline{Equalization}$\n",
    "\n",
    "Distributions are often skewed toward low intensities in medical images due to background values. **Equalization** redistributes values to optimize full intesntiy range. \n",
    "\n",
    "The way to do this by taking the rolling sum and dividing by the sum of the histogram. We do this via the cumulative density function or **cdf**, which is calculated as **255* hist.cumsum()/hist.sum()**\n",
    "\n",
    "Let's practice: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the hand radiograph\n",
    "im = imageio.imread('hand-xray.jpg')\n",
    "print('Data type:', im.dtype)\n",
    "print('Min. value:', im.min())\n",
    "print('Max value:', im.max())\n",
    "\n",
    "# Plot the grayscale image\n",
    "plt.imshow(im, vmin = 0, vmax = 255)\n",
    "plt.colorbar()\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SciPy's \"ndimage\" module\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "# Create a histogram, binned at each possible value\n",
    "hist = ndi.histogram(im, bins = 256, min = 0, max = 255)\n",
    "\n",
    "# Create a cumulative distribution function\n",
    "cdf = hist.cumsum() / hist.sum()\n",
    "\n",
    "# Plot the histogram and CDF\n",
    "fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "axes[0].plot(hist, label='Histogram')\n",
    "axes[1].plot(cdf, label='CDF')\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of above code: \n",
    "\n",
    "<img src=\"eqhist.JPG\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masks\n",
    "\n",
    "Masks are a boolean array that segments out areas of an image that are of interest. Often, this is done via applying some sort of condition.\n",
    "\n",
    "Masks can be used to scree images, allowing original values to be passed through while excluding those pixels that do not meet the condition. For this, the **np.where()** function is highly useful. \n",
    "\n",
    "**np.where(condition, x, y)** looks at a *condition* and returns x if True and y if False. \n",
    "\n",
    "Masks will rarely be perfect and will sometimes leave out edges (which for various reasons can be \"fuzzy\"). In order to solve this \"fuzzy edge\" problem, we can do something called a **dilation** via the **ndi.binary_dilation(mask, iterations = )** function. This takes all the pixels adjacent to the mask pixels, and appends them to the mask. This is a good way of capturing pixels that may have otherwise escaped. \n",
    "\n",
    "The opposite task, **binary erosion**, is implemented via **ndi.biny_erosion(mask, iterations = )**. This cuts the mask down to its most central pixels. \n",
    "\n",
    "Binary erosion and binary dilation can be combined to open/close holes in your mask. These are found in the following functions: \n",
    "\n",
    "**binary_opening()** (open areas near edges)\n",
    "**binary_closing()** (fill in holes near edge)\n",
    "\n",
    "\n",
    "Let's practice making skin and bone masks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create skin and bone masks\n",
    "mask_bone = im>=145\n",
    "mask_skin = (im>=45) & (im < 145)\n",
    "\n",
    "# Plot the skin (0) and bone (1) masks\n",
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(mask_skin, cmap = 'gray')\n",
    "axes[1].imshow(mask_bone, cmap = 'gray')\n",
    "format_and_render_plot()\n",
    "\n",
    "# Import SciPy's \"ndimage\" module\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "# Screen out non-bone pixels from \"im\"\n",
    "mask_bone = im >=145\n",
    "im_bone = np.where(mask_bone, im,0)\n",
    "\n",
    "# Get the histogram of bone intensities\n",
    "hist = ndi.histogram(im_bone, min = 1, max = 255, bins = 255)\n",
    "\n",
    "# Plot masked image and histogram\n",
    "fig, axes = plt.subplots(2,1)\n",
    "axes[0].imshow(im_bone)\n",
    "axes[1].plot(hist)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"masks.JPG\">\n",
    "\n",
    "<img src = \"masks_applied.JPG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and tune bone mask\n",
    "mask_bone = im >= 145\n",
    "mask_dilate = ndi.binary_dilation(mask_bone, iterations = 5)\n",
    "mask_closed = ndi.binary_closing(mask_bone,iterations = 5)\n",
    "\n",
    "# Plot masked images\n",
    "fig, axes = plt.subplots(1,3)\n",
    "axes[0].imshow(mask_bone)\n",
    "axes[1].imshow(mask_dilate)\n",
    "axes[2].imshow(mask_closed)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"open_close.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters: \n",
    "\n",
    "We can run convolutions to smooth or sharpen images, depending on our kernel structure. Smoothing can improve the signal-to-noise ratio of your image by blurring out small variations in intensity.\n",
    "\n",
    "$\\underline{Filter\\ Structures}:$\n",
    "\n",
    "We can make a custom kernel using a numpy array and then use **ndi.convolve(im,filter)** in order to run our convolution. \n",
    "\n",
    "Alternatively, we can filter individua pixels in the following ways: \n",
    "\n",
    "a) ndimage.median_filter() (takes the median of surrounding pixels)\n",
    "\n",
    "b) ndimage.uniform_filter()\n",
    "\n",
    "c) ndimage.maximum_filter()\n",
    "\n",
    "d) ndimage.percentile_filter()\n",
    "\n",
    "(All of these can be as large as you want...)\n",
    "\n",
    "We can also apply a **Gaussian Filter**. This blurs activation around a central point in a Gaussian way (see illustration) such that closer pixels contribute more weight. Setting the size of the sigma parameter tells us how wide the Gaussian map extends. Careful, though, as too large a sigma can make a blurry image.\n",
    "\n",
    "The Gaussian filter is great for smoothing!\n",
    "\n",
    "<img src = \"Gauss.JPG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filter weights\n",
    "weights = [[0.11, 0.11, 0.11],\n",
    "           [0.11, 0.11, 0.11], \n",
    "           [0.11, 0.11, 0.11]]\n",
    "\n",
    "# Convolve the image with the filter\n",
    "im_filt = ndi.convolve(im, weights)\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(im)\n",
    "axes[1].imshow(im_filt)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth \"im\" with Gaussian filters\n",
    "im_s1 = ndi.gaussian_filter(im, sigma=1)\n",
    "im_s3 = ndi.gaussian_filter(im,sigma=3)\n",
    "\n",
    "# Draw bone masks of each image\n",
    "fig, axes = plt.subplots(1,3)\n",
    "axes[0].imshow(im >= 145)\n",
    "axes[1].imshow(im_s1 >= 145)\n",
    "axes[2].imshow(im_s3 >= 145)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Detection: \n",
    "\n",
    "How might we detect featuers of an image such as edges?\n",
    "\n",
    "$\\underline{Edge\\ detection}$\n",
    "\n",
    "Keep in mind that edges are abrupt changes in intensity along an axis. But what kernel structure to employ? \n",
    "\n",
    "Luckily, this is a well-trodden area. And we can often just Sobel filters (see below, and illustration) \n",
    "\n",
    "<img src = \"sobel.JPG\">\n",
    "\n",
    "However, each of these filters will only give us horizontal and vertical edges, respectively. What if we want to calculate edges of any orientation? Luckily, for this, we can combine Sobel filters using the Pythagorean theorem: \n",
    "\n",
    "eg: \n",
    "\n",
    "edges0 = ndi.sobel(im,axis=0)\n",
    "edges1 = ndi.sobel(im,axis=1)\n",
    "edges = np.sqrt(np.square(edges0) +np.square(edges1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weights to detect vertical edges\n",
    "weights = [[1,0,-1], [1,0,-1], [1,0,-1]]\n",
    "\n",
    "# Convolve \"im\" with filter weights\n",
    "edges = ndi.convolve(im,weights)\n",
    "\n",
    "# Draw the image in color\n",
    "plt.imshow(edges, cmap = 'seismic', vmin=-150, vmax=150)\n",
    "plt.colorbar()\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"sobel_hand.JPG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Sobel filter along both axes\n",
    "sobel_ax0 = ndi.sobel(im, axis=0)\n",
    "sobel_ax1 = ndi.sobel(im,axis=1)\n",
    "\n",
    "# Calculate edge magnitude \n",
    "edges = edges = np.sqrt(np.square(sobel_ax0) +np.square(sobel_ax1))\n",
    "\n",
    "# Plot edge magnitude\n",
    "plt.imshow(edges, cmap='gray', vmax=75)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"alledges.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objects and labels: Segmentation and Analysis\n",
    "\n",
    "The ejection fraction: the proportion of blood pumped out of the heart's left ventricle\n",
    "\n",
    "When we have a segmented image (created using a filter/mask), we can then use scipy's **ndi.label()** function. We can then label the mask!\n",
    "\n",
    "This will return a list of tuples with (label_number, label_name). \n",
    "\n",
    "If you want to select out a labeled portion of an image, you can then use **np.where(labels == ...), im, 0)**\n",
    "\n",
    "$\\underline{Bounding\\ Boxes?}$\n",
    "\n",
    "The **ndi.find_objects()** function returns a list of bounding box coordinates. If you then go through that list (indexing in the usual way with []), you will get out successive tuples that list off the coordinates of each box (see slides). You can then index into your image with the bounding box coordinates to get out individual objects. \n",
    "\n",
    "Let's practice on an image of the heart below.  This is starting to resemble a full image analysis pipeline!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth intensity values\n",
    "im_filt = ndi.median_filter(im, size=3)\n",
    "\n",
    "# Select high-intensity pixels\n",
    "mask_start = np.where(im_filt > 60, 1, 0)\n",
    "mask = ndi.binary_closing(mask_start)\n",
    "\n",
    "# Label the objects in \"mask\"\n",
    "labels, nlabels = ndi.label(mask)\n",
    "print('Num. Labels:', nlabels)\n",
    "\n",
    "# Create a `labels` overlay\n",
    "overlay = np.where(labels > 0, labels, np.nan)\n",
    "\n",
    "# Use imshow to plot the overlay\n",
    "plt.imshow(overlay, cmap='rainbow', alpha=0.75)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"labeled_data.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are like object \"handles\" - they give you a way to pick up whole sets of pixels at a time. To select a particular object:\n",
    "\n",
    "Find the label value associated with the object.\n",
    "Create a mask of matching pixels.\n",
    "For this exercise, create a labeled array from the provided mask. Then, find the label value for the centrally-located left ventricle, and create a mask for it.\n",
    "\n",
    "When running ndi.label(), note that image traversed from top-left to bottom-right.You may need to plot your labeled image to get the appropriate region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the image \"mask\"\n",
    "labels, nlabels = ndi.label(mask)\n",
    "\n",
    "# Select left ventricle pixels\n",
    "lv_val = labels[128, 128]\n",
    "lv_mask = np.where(labels==lv_val,1,np.nan)\n",
    "\n",
    "# Overlay selected label\n",
    "plt.imshow(lv_mask, cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"lvyn.JPG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create left ventricle mask\n",
    "labels, nlabels = ndi.label(mask)\n",
    "lv_val = labels[128, 128]\n",
    "lv_mask = np.where(labels == lv_val, 1, 0)\n",
    "\n",
    "# Find bounding box of left ventricle\n",
    "bboxes = ndi.find_objects(lv_mask)\n",
    "print('Number of objects:', len(bboxes))\n",
    "print('Indices for first box:', bboxes[0])\n",
    "\n",
    "# Crop to the left ventricle (index 0)\n",
    "im_lv = im[bboxes[0]]\n",
    "\n",
    "# Plot the cropped image\n",
    "plt.imshow(im_lv)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"lvp.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Intensity\n",
    "\n",
    "Once objects have been segregated from the background, you can call all sorts of dope measurements on them using scipy. \n",
    "\n",
    "Scipy has conveniently adapted common statistics to image data, adn will apply functions over all dimensions or at specific labels if you are interested in them. Some important ones are as followS: \n",
    "\n",
    "ndi.mean()\n",
    "ndi.median()\n",
    "ndi.sum()\n",
    "ndi.maximum()\n",
    "ndi.standard_deviation()\n",
    "ndi.variance()\n",
    "\n",
    "If you have a volume and series of labels, you can customize your function calls. Eg: **ndi.mean(vol,label,index=1)** will do the following: 1) Take the mean of pixels in the volume labeled #1. \n",
    "\n",
    "\n",
    "You can also run discrete object histograms. For instance, **obj_hists = ndi.histogram(vol,0,255,256,labels,index = [1,2])** will return a histogram from 0 to 255 with 256 bins of the objects labeled 1 and 2. \n",
    "\n",
    "Object-level histograms can be a great way to evaluate your segmentation, as a good segmentation should yield a histogram free of peaks and valleys (which could indicate the \"infiltration\" of other tissue types). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance for all pixels\n",
    "var_all = ndi.variance(vol, labels=None, index=None)\n",
    "print('All pixels:', var_all)\n",
    "\n",
    "# Variance for labeled pixels\n",
    "var_labels = ndi.variance(vol, labels, index=None)\n",
    "print('Labeled pixels:', var_labels)\n",
    "\n",
    "# Variance for each object\n",
    "var_objects = ndi.variance(vol, labels, index=[1,2])\n",
    "print('Left ventricle:', var_objects[0])\n",
    "print('Other tissue:', var_objects[1])\n",
    "\n",
    "\n",
    "\n",
    "# Create histograms for selected pixels\n",
    "hist1 = ndi.histogram(vol, min=0, max=255, bins=256)\n",
    "hist2 = ndi.histogram(vol, 0, 255, 256, labels=labels)\n",
    "hist3 = ndi.histogram(vol, 0, 255, 256, labels=labels, index=1)\n",
    "\n",
    "\n",
    "\n",
    "# Create histograms for selected pixels\n",
    "hist1 = ndi.histogram(vol, min=0, max=255, bins=256)\n",
    "hist2 = ndi.histogram(vol, 0, 255, 256, labels=labels)\n",
    "hist3 = ndi.histogram(vol, 0, 255, 256, labels=labels, index=1)\n",
    "\n",
    "# Plot the histogram density\n",
    "plt.plot(hist1 / hist1.sum(), label='All pixels')\n",
    "plt.plot(hist2 / hist2.sum(), label='All labeled pixels')\n",
    "plt.plot(hist3 / hist3.sum(), label='Left ventricle')\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"histograms.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny = (3, 2)\n",
    "x = np.linspace(0, 1, nx)\n",
    "y = np.linspace(0, 1, ny)\n",
    "xv, yv = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[1] [0]\n"
     ]
    }
   ],
   "source": [
    "diff_table = xv-yv\n",
    "print(type(diff_table))\n",
    "\n",
    "idx1,idx2 = np.where(diff_table == np.min(diff_table))\n",
    "\n",
    "print(idx1,idx2)\n",
    "x[idx1],y[idx2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5]\n"
     ]
    }
   ],
   "source": [
    "print(x[idx1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.5  1. ]\n",
      " [-1.  -0.5  0. ]]\n"
     ]
    }
   ],
   "source": [
    "print(diff_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=3)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "bslist1 = ['01/01/2019','08/05/2015','06/07/2011']\n",
    "bslist1_dt = []\n",
    "\n",
    "for i in bslist1:\n",
    "    i = datetime.strptime(i,'%m/%d/%Y')\n",
    "    bslist1_dt.append(i)\n",
    "    \n",
    "bslist2 = ['01/04/2019','11/05/2015','12/07/2011']\n",
    "bslist2_dt = []\n",
    "\n",
    "for i in bslist2:\n",
    "    i = datetime.strptime(i,'%m/%d/%Y')\n",
    "    bslist2_dt.append(i)\n",
    "\n",
    "    \n",
    "XX,YY = np.meshgrid(bslist1_dt,bslist2_dt)\n",
    "\n",
    "diff_table = abs(XX-YY)\n",
    "np.min(diff_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
